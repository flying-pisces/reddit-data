# Reddit Data Engine - Test Suite ðŸ§ª

Comprehensive test suite for the Reddit Data Engine with unit tests, integration tests, and performance benchmarks.

## Test Structure

```
tests/
â”œâ”€â”€ __init__.py              # Test package initialization
â”œâ”€â”€ conftest.py              # Pytest configuration and fixtures
â”œâ”€â”€ test_reddit_client.py    # Reddit client tests
â”œâ”€â”€ test_data_processor.py   # Data processing tests
â”œâ”€â”€ test_api_interface.py    # API interface tests
â”œâ”€â”€ test_integration.py      # End-to-end integration tests
â”œâ”€â”€ test_all.py              # Main test runner
â”œâ”€â”€ requirements-test.txt    # Testing dependencies
â””â”€â”€ README.md               # This file
```

## Running Tests

### Install Test Dependencies

```bash
cd tests
pip install -r requirements-test.txt
```

### Run All Tests

```bash
# Run complete test suite
python -m pytest test_all.py -v

# Run with coverage
python -m pytest test_all.py -v --cov=../ --cov-report=html

# Run specific test file
python -m pytest test_reddit_client.py -v

# Run integration tests only
python test_integration.py
```

### Run Tests in Parallel

```bash
# Run tests across multiple cores
python -m pytest -n auto test_all.py
```

## Test Categories

### ðŸ”§ Unit Tests

**Reddit Client Tests (`test_reddit_client.py`)**
- RedditPost dataclass functionality
- Synchronous Reddit client operations
- Asynchronous Reddit client operations
- Error handling and recovery
- Rate limiting compliance

**Data Processor Tests (`test_data_processor.py`)**
- Post processing and analysis
- Ticker extraction from content
- Sentiment analysis algorithms
- Speculative post detection
- Data export functionality
- Cleanup and memory management

**API Interface Tests (`test_api_interface.py`)**
- Analysis API functionality
- Simple API wrapper
- Data export formats
- Real-time feed generation
- Custom data queries

### ðŸ”„ Integration Tests (`test_integration.py`)

**End-to-End Flow**
- Complete data pipeline testing
- API integration with data processor
- Configuration integration across components
- Monitor system integration

**Performance Tests**
- High-volume post processing (1000+ posts)
- Concurrent processing capabilities
- Memory usage optimization
- Export performance benchmarks

**Error Handling**
- API error recovery mechanisms
- Malformed data handling
- Network failure resilience

## Test Fixtures

### Core Fixtures (in `conftest.py`)

- `sample_reddit_post` - Single test post with realistic data
- `sample_reddit_posts` - Multiple test posts with different tickers
- `mock_reddit_client` - Mock Reddit client for isolated testing
- `mock_async_reddit_client` - Mock async Reddit client
- `temp_data_dir` - Temporary directory for test data
- `test_config` - Test configuration with mock API credentials
- `capture_logs` - Log capture for testing log output

### Mock Objects

- `MockPrawSubmission` - Simulates PRAW submission objects
- `MockAsyncSubmission` - Simulates async PRAW submissions

## Test Data

### Sample Posts
Tests use realistic Reddit post data including:
- Stock ticker mentions (`$AAPL`, `$TSLA`, `$GME`)
- Various subreddits (`wallstreetbets`, `stocks`, `investing`)
- Speculative vs. analytical content
- Different engagement levels (scores, comments)
- Recent vs. older posts

### Mock API Responses
- Trending ticker data
- Sentiment analysis results
- Subreddit activity metrics
- Priority post detection

## Test Coverage

Current test coverage includes:

âœ… **Reddit Client** (90%+ coverage)
- Post fetching and parsing
- Category classification
- Error handling
- Async operations

âœ… **Data Processor** (95%+ coverage)  
- Ticker extraction
- Sentiment analysis
- Speculative detection
- Data export
- Memory management

âœ… **API Interface** (85%+ coverage)
- Data retrieval methods
- Export functionality
- Simple API wrapper
- Custom queries

âœ… **Integration** (80%+ coverage)
- End-to-end workflows
- Component integration
- Performance testing
- Error scenarios

## Performance Benchmarks

### Processing Performance
- **1,000 posts**: < 5 seconds processing time
- **Data export**: < 2 seconds for full dataset
- **Memory usage**: < 100MB for typical workload

### Concurrency
- **5 parallel processors**: 100 posts each simultaneously
- **Async operations**: Multiple subreddit monitoring
- **Thread safety**: Concurrent data access

## Continuous Integration

### GitHub Actions (if configured)
```yaml
- Run tests on Python 3.8, 3.9, 3.10, 3.11
- Test on Ubuntu, macOS, Windows
- Generate coverage reports
- Performance regression testing
```

### Test Automation
- **Pre-commit hooks**: Run fast tests before commits
- **Nightly builds**: Full test suite including performance
- **Release testing**: Comprehensive validation before releases

## Mock Testing Strategy

### Reddit API Mocking
- No real Reddit API calls during testing
- Consistent, predictable test data
- Fast test execution
- Offline testing capability

### Data Persistence Mocking
- Temporary directories for file operations
- In-memory data structures
- Cleanup after each test

## Writing New Tests

### Test Naming Convention
```python
def test_component_functionality_scenario():
    """Test description explaining what is being tested"""
    # Arrange
    # Act  
    # Assert
```

### Async Test Pattern
```python
@pytest.mark.asyncio
async def test_async_functionality():
    """Test async operations"""
    async with AsyncRedditClient() as client:
        result = await client.some_async_method()
        assert result is not None
```

### Integration Test Pattern
```python
def test_end_to_end_workflow(temp_data_dir):
    """Test complete workflow from input to output"""
    # Setup components
    # Process data through pipeline  
    # Verify final output
```

## Debugging Failed Tests

### Common Issues

1. **Import Errors**
   - Check Python path configuration
   - Verify all dependencies installed

2. **Async Test Failures**
   - Ensure `pytest-asyncio` is installed
   - Check event loop configuration

3. **File Permission Errors**
   - Verify temp directory cleanup
   - Check file system permissions

4. **Network-Related Failures**
   - Ensure all external API calls are mocked
   - Check offline testing configuration

### Debug Commands
```bash
# Run single test with full output
python -m pytest test_file.py::test_name -v -s

# Run with pdb debugger
python -m pytest --pdb test_file.py::test_name

# Show fixture values
python -m pytest --fixtures test_file.py
```

## Contributing to Tests

### Adding New Tests
1. Follow existing patterns and naming conventions
2. Include both positive and negative test cases
3. Mock external dependencies appropriately
4. Add performance tests for new features
5. Update this README with new test descriptions

### Test Quality Guidelines
- **Clear test names** that describe the scenario
- **Isolated tests** that don't depend on each other
- **Fast execution** (< 1 second per test)
- **Deterministic results** (no random failures)
- **Good coverage** of edge cases and error conditions